13:34 Introduction of EMPAIA/xAI
correspondence between medical expertise on human side

13:40 How do you teach Pathologists to understand AI?
13:42 What kind of experience/expertise can be "taught" to AI?
13:44 Knowledge can not be nicely packed in decision trees since it is too complex
13:47 Adversarial attacks show that we make decisions differently than AIs do
13:48 Lack of ML expertise on AI researcher side
13:51 Path think about offloading easy tasks and having a comparable standard for that. Isnt this dangerous? Metaphor of "calculator", that is precise results. Better use "autopilot"?
13:52 current AI = intern that does easy tasks. Next gen AI = colleague that can do different tasks
13:59 Antromorphosize AI solutions should be prevented - raises too many expectations (communication, understanding). Calculators are too deterministic too. 
Better metaphor: chicken/ape that has been taught to recognize cancer cells based on images - did not understand concepts but just example images.
14:05 Validation is an important point. Error points: human error in validation, false positives (ie. for cancer treatment), some  can't be directly validated
14:09 Validation has different meanings - data set, result correction (adding images to validation data set, continually refining boundary - include adversarial examples in dataset to make AI more robust)
14:16 Cant explain statistical models now since they dont jive with our understanding, force complex situation into other domain/representation - converge on same internal representation
14:21 What is the same internal representation? -> also in form of association nets? How does knowledge representation work?
14:26 Names given to disease mechanism dont always correspond to the actual mechanism - just how we make decisions.
14:28 Problem of structurized reporting in Pathologists for having unified language