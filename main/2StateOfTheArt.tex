\section{State of the art}
\label{sec:SOA}

\cite{holzinger_artificial_2020} and \cite{piccialli_survey_2021} (guest editor paper) state of the art on AI applications in medicine and growing prevalence of AI solutions in medicine

\cite{piccialli_artificial_2021} (two guest editors on this one) and \cite{HolzingerEtAl:2021:GraphFusion} for the future direction of AI approaches in medicine, combining data over time and from multiple modalities, dramatically increasing the need for explainability/causability, as the total model input cannot be simply inspected by a user (as is currently the case)

\cite{tjoa_survey_2020} for state of the art in XAI solutions for medicine, highlights the shortcomings of an algorithm-focused research landscape in addressing explainability needs of users in practice

\cite{poceviciute_survey_2020} for the most pathology-specific analysis of XAI approaches, basis for building the explanation classes

\cite{bodria_benchmarking_2021} (could also be introduced in case study design) introduces explanation classes and benchmarks for the evaluation of XAI approaches

Also to include: 
\begin{itemize}
\item current regulatory landscape wrt. explainability for AI solutions
\item state of the art for (selected) technical implementations of explainability?
\end{itemize}


ui subsection:
show old ui rules
keep human in control as per eu regulation
ai is not really integrated into old hci, need a new ai ui connection
\cite{tosun_histomapr_2020} XAI UI for pathology